# ğŸ–¥ï¸ Suporte de Hardware - GPU/CPU/MPS

## ğŸ“‹ Dispositivos Suportados

Este projeto suporta automaticamente:

| Dispositivo | Tipo | Performance | Status |
|------------|------|-------------|--------|
| **NVIDIA GPU** | CUDA | MÃ¡xima (10-30x CPU) | âœ… Suportado |
| **Intel GPU** | XPU (Arc/Iris Xe) | Muito Alta (5-15x CPU) | âœ… Suportado |
| **Apple Silicon** | MPS (M1/M2/M3/M4) | Alta (5-10x CPU) | âœ… Suportado |
| **Intel CPU** | CPU + VNNI | BÃ¡sica | âœ… Suportado |
| **AMD CPU** | CPU + AVX2 | BÃ¡sica | âœ… Suportado |
| **Apple CPU** | CPU | BÃ¡sica | âœ… Suportado |

---

## ğŸš€ Detectar Hardware DisponÃ­vel

### 1. Verificar Dispositivos

```bash
python check_device.py
```

**Resultado esperado:**

```
ğŸ”§ DIAGNÃ“STICO DE HARDWARE - CPPNCRIPTO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PYTORCH - VERIFICAÃ‡ÃƒO DE DISPOSITIVOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ PyTorch versÃ£o: 2.2.0

ğŸ“Œ CPU:
   â€¢ DisponÃ­vel: Sim
   â€¢ Cores: 8

ğŸ”· NVIDIA CUDA:
   âœ“ DisponÃ­vel: SIM
   â€¢ VersÃ£o CUDA: 12.1
   â€¢ cuDNN versÃ£o: 8804
   â€¢ GPUs detectadas: 1
     - 0: NVIDIA GeForce RTX 4090

ğŸ APPLE METAL (M1/M2/M3/M4):
   âœ— DisponÃ­vel: NÃƒO

ğŸ’  INTEL GPU (Arc, Iris Xe):
   âœ— DisponÃ­vel: NÃƒO
```

### 2. Testar e ForÃ§ar Dispositivos

```bash
python test_device_override.py
```

**Menu interativo:**
```
ğŸ“‹ Menu:
  1. Testar CPU
  2. Testar CUDA (NVIDIA GPU)
  3. Testar MPS (Apple Metal)
  4. Testar XPU (Intel GPU)
  5. Benchmark - Comparar todos os devices
  6. Verificar Device AutomÃ¡tico
  7. Sair
```

---

## ğŸ”§ Configurar Device EspecÃ­fico

### OpÃ§Ã£o 1: Auto-detecÃ§Ã£o (Recomendado)

```python
from src.config import config

# Detecta automaticamente o melhor device
print(f"Device: {config.device}")  # cuda, mps, xpu ou cpu
```

### OpÃ§Ã£o 2: ForÃ§ar Device

```python
from src.config import config

# ForÃ§ar CPU
config.device = "cpu"

# ForÃ§ar CUDA (se disponÃ­vel)
config.device = "cuda"

# ForÃ§ar MPS (Apple)
config.device = "mps"

# ForÃ§ar XPU (Intel)
config.device = "xpu"
```

### OpÃ§Ã£o 3: VariÃ¡vel de Ambiente

```bash
# Linux/Mac
export PYTORCH_DEVICE=cuda
export PYTORCH_DEVICE=mps
export PYTORCH_DEVICE=xpu

# Windows PowerShell
$env:PYTORCH_DEVICE="cuda"
```

---

## ğŸ“Š Performance Comparativa

### Treino de MacroNet (1 epoch, 1440 candles)

```
NVIDIA RTX 4090:    0.5 - 1.0 segundo
NVIDIA RTX 4080:    1.0 - 2.0 segundos
Intel Arc A770:     1.5 - 3.0 segundos
Apple M3 Max:       2.0 - 4.0 segundos
Apple M2:           3.0 - 6.0 segundos
Intel Iris Xe:      5.0 - 10.0 segundos
CPU (8-core):       10.0 - 30.0 segundos
CPU (4-core):       30.0 - 60.0 segundos
```

### Backtest (30 dias completos)

```
NVIDIA RTX 4090:    5 - 10 segundos
NVIDIA RTX 4080:    10 - 20 segundos
Intel Arc A770:     20 - 40 segundos
Apple M3 Max:       30 - 60 segundos
CPU (8-core):       2 - 5 minutos
CPU (4-core):       5 - 10 minutos
```

---

## ğŸ”§ InstalaÃ§Ã£o por Tipo de GPU

### NVIDIA GPU (CUDA)

**1. Verificar GPU:**
```bash
# Windows
nvidia-smi

# Linux/Mac
nvcc --version
```

**2. Instalar CUDA Toolkit:**
- Baixar: https://developer.nvidia.com/cuda-downloads
- Instalar seguindo instruÃ§Ãµes oficiais

**3. Instalar PyTorch com CUDA:**
```bash
# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**4. Verificar instalaÃ§Ã£o:**
```python
import torch
print(torch.cuda.is_available())  # True
print(torch.cuda.get_device_name(0))  # Nome da GPU
```

---

### Intel GPU (Arc/Iris Xe)

**1. InstalaÃ§Ã£o no Windows:**
```bash
# Intel Arc GPUs (Windows)
pip install intel-extension-for-pytorch

# Depois instalar PyTorch normalmente
pip install -r requirements.txt
```

**2. InstalaÃ§Ã£o no Linux:**
```bash
# Intel Extension for PyTorch
pip install intel-extension-for-pytorch

# Verificar
python -c "import intel_extension_for_pytorch as ipex; print(ipex.__version__)"
```

**3. Usar no cÃ³digo:**
```python
import torch
import intel_extension_for_pytorch as ipex

device = torch.device("xpu")

# Modelo no XPU
model = model.to(device)
model = ipex.optimize(model)
```

### Nota rÃ¡pida - InstalaÃ§Ã£o no Windows PowerShell

```powershell
# No PowerShell (recomendado):
pip install intel-extension-for-pytorch

# Depois, feche o terminal/IDE e reabra para que o Python carregue ipex corretamente
```

---

### Apple Silicon (M1/M2/M3/M4)

**1. VerificaÃ§Ã£o automÃ¡tica:**
```bash
# PyTorch jÃ¡ tem suporte MPS nativo
python -c "import torch; print(torch.backends.mps.is_available())"
```

**2. Funciona automaticamente:**
```python
import torch

device = torch.device("mps")  # Ou deixar auto-detectar
model = model.to(device)
```

**3. Se nÃ£o funcionar:**
```bash
# Atualizar PyTorch
pip install --upgrade torch

# Ou reinstalar especificamente para Mac
pip install --upgrade torch torchvision torchaudio
```

---

## ğŸ§ª Testes de VerificaÃ§Ã£o

### Teste RÃ¡pido

```bash
python quick_tests.py
```

### Teste com Device EspecÃ­fico

```python
from src.config import config
from src.pipeline import TradingPipeline

# ForÃ§ar device
config.device = "cuda"  # ou "mps", "xpu", "cpu"

# Testar
pipeline = TradingPipeline()
signal = pipeline.predict_signal("BTCUSDT")
print(f"Signal: {signal:.4f} (em {config.device})")
```

---

## âš¡ OtimizaÃ§Ãµes por Device

### CUDA (NVIDIA)

```python
import torch

# Auto-tuning
torch.backends.cudnn.benchmark = True

# Usar float16 para melhor performance
model = model.half()
```

### MPS (Apple)

```python
import torch

# MPS Ã© otimizado automaticamente
# Usar mixed precision
from torch.cuda.amp import GradScaler

scaler = GradScaler()
```

### XPU (Intel)

```python
import intel_extension_for_pytorch as ipex
import torch

# Otimizar modelo
model = ipex.optimize(model)

# Usar Automatic Mixed Precision
model.train()
```

---

## ğŸ› Troubleshooting

### Problema: "CUDA not available" mas tenho GPU

**SoluÃ§Ã£o:**
```bash
# 1. Verificar driver NVIDIA
nvidia-smi

# 2. Reinstalar CUDA Toolkit
# Baixe de: https://developer.nvidia.com/cuda-downloads

# 3. Reinstalar PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Problema: "MPS not available" no Mac

**SoluÃ§Ã£o:**
```bash
# 1. Atualizar PyTorch
pip install --upgrade torch

# 2. Usar CPU por enquanto
# Vai funcionar, mas mais lento
```

### Problema: "XPU not found" no Intel

**SoluÃ§Ã£o:**
```bash
# 1. Instalar Intel Extension
pip install intel-extension-for-pytorch

# 2. Verificar instalaÃ§Ã£o
python -c "import intel_extension_for_pytorch; print('OK')"

# 3. Se nÃ£o funcionar, usar CPU
config.device = "cpu"
```

### Problema: Out of Memory (OOM)

**SoluÃ§Ã£o:**
```python
# Reduzir batch size
config.macronet.batch_size = 8  # Ao invÃ©s de 32

# Usar menor embedding_dim
config.macronet.embedding_dim = 64  # Ao invÃ©s de 128

# Usar CPU ao invÃ©s de GPU
config.device = "cpu"
```

---

## ğŸ“ˆ Monitoramento de Performance

### Durante Treino

```python
import torch
from src.pipeline import TradingPipeline

pipeline = TradingPipeline()

# Monitor GPU (NVIDIA)
if torch.cuda.is_available():
    print(f"GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
    print(f"GPU Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB")

# Monitor CPU
import psutil
memory = psutil.virtual_memory()
print(f"RAM: {memory.percent}%")
```

### Logs de Performance

```python
from src.logger import get_logger

logger = get_logger(__name__)

logger.info("training_start", device=config.device)
# ... treinamento ...
logger.info("training_end", device=config.device, time_seconds=elapsed)
```

---

## ğŸ¯ RecomendaÃ§Ãµes

| SituaÃ§Ã£o | Recomendado |
|----------|------------|
| Desenvolvimento local | CPU ou MPS (Mac) |
| ProduÃ§Ã£o pequena | Intel GPU ou CPU |
| ProduÃ§Ã£o mÃ©dia | NVIDIA RTX 4080 |
| ProduÃ§Ã£o grande | NVIDIA RTX 4090 ou A100 |
| Laptop Mac | MPS (automÃ¡tico) |
| Laptop Intel | CPU ou Intel Arc (se tiver) |
| Servidor Linux | NVIDIA CUDA |

---

**Ãšltima atualizaÃ§Ã£o:** Novembro 2025
