# üßÆ Alternativas de F√≥rmulas de Fitness

## üìä F√≥rmula Atual (Linear)

```python
reward = (prediction_value * 100) * (price_change_pct * 100)
```

**Problema**: Escala linear n√£o diferencia bem confian√ßa alta em movimentos grandes.

---

## üöÄ 5 Alternativas Melhoradas

### **Alternativa 1: Quadr√°tica com Bonus de Confian√ßa** ‚≠ê RECOMENDADA

```python
def fitness_quadratic_confidence(prediction, price_change_pct):
    """
    Premeia quadraticamente previs√µes confiantes corretas.
    Penaliza quadraticamente previs√µes confiantes erradas.
    
    Escala: -10,000 a +10,000 (10x maior que linear)
    """
    # Normalizar prediction para [-1, 1]
    pred_norm = np.clip(prediction, -1, 1)
    
    # Magnitude da previs√£o (confian√ßa) - sempre positiva
    confidence = abs(pred_norm)
    
    # Dire√ß√£o: previs√£o e mudan√ßa no mesmo sentido?
    direction_match = np.sign(pred_norm) == np.sign(price_change_pct)
    
    # Base reward linear
    base_reward = pred_norm * price_change_pct * 10000
    
    # Bonus quadr√°tico para alta confian√ßa + acerto
    if direction_match:
        confidence_bonus = (confidence ** 2) * abs(price_change_pct) * 5000
        reward = base_reward + confidence_bonus
    else:
        # Penalidade quadr√°tica para alta confian√ßa + erro
        confidence_penalty = (confidence ** 2) * abs(price_change_pct) * 5000
        reward = base_reward - confidence_penalty
    
    return reward

# Exemplos:
# Alta confian√ßa + acerto: pred=0.9, change=+0.5%
#   base = 0.9 √ó 0.005 √ó 10000 = 45
#   bonus = 0.81 √ó 0.005 √ó 5000 = 20.25
#   total = 65.25 (vs 45 linear)
#
# Alta confian√ßa + erro: pred=0.9, change=-0.5%
#   base = 0.9 √ó -0.005 √ó 10000 = -45
#   penalty = 0.81 √ó 0.005 √ó 5000 = 20.25
#   total = -65.25 (castigo maior!)
```

**Caracter√≠sticas**:
- ‚úÖ Premia **quadraticamente** alta confian√ßa + acerto
- ‚úÖ Penaliza **quadraticamente** alta confian√ßa + erro
- ‚úÖ Diferencia√ß√£o clara entre confian√ßa baixa/m√©dia/alta
- ‚úÖ Escala ~10x maior que linear
- ‚úÖ Incentiva modelo a ter convic√ß√£o quando tem certeza

---

### **Alternativa 2: Exponencial com Threshold**

```python
def fitness_exponential_threshold(prediction, price_change_pct):
    """
    Crescimento exponencial para movimentos grandes.
    Threshold para ignorar ru√≠do pequeno.
    
    Escala: -50,000 a +50,000 (50x maior em extremos)
    """
    pred_norm = np.clip(prediction, -1, 1)
    
    # Threshold: ignorar movimentos < 0.1%
    if abs(price_change_pct) < 0.001:
        return 0.0
    
    # Base
    base = pred_norm * price_change_pct * 10000
    
    # Exponencial para movimentos grandes
    magnitude = abs(price_change_pct)
    confidence = abs(pred_norm)
    direction_match = np.sign(pred_norm) == np.sign(price_change_pct)
    
    if direction_match:
        # e^(confidence √ó magnitude √ó 100) - 1
        exponential_bonus = (np.exp(confidence * magnitude * 100) - 1) * 1000
        reward = base + exponential_bonus
    else:
        exponential_penalty = (np.exp(confidence * magnitude * 100) - 1) * 1000
        reward = base - exponential_penalty
    
    return np.clip(reward, -50000, 50000)

# Exemplos:
# Movimento grande (1%): pred=0.8, change=+1%
#   base = 0.8 √ó 0.01 √ó 10000 = 80
#   exp_bonus = (e^0.8 - 1) √ó 1000 ‚âà 1,225
#   total ‚âà 1,305 (vs 80 linear!)
#
# Movimento pequeno (0.1%): pred=0.8, change=+0.1%
#   base = 0.8 √ó 0.001 √ó 10000 = 8
#   exp_bonus = (e^0.08 - 1) √ó 1000 ‚âà 83
#   total ‚âà 91
```

**Caracter√≠sticas**:
- ‚úÖ **Exponencial** para movimentos grandes
- ‚úÖ Ignora ru√≠do (threshold 0.1%)
- ‚úÖ Escala muito maior (~50x em extremos)
- ‚ö†Ô∏è Pode ser inst√°vel se n√£o clipar
- ‚úÖ Incentiva foco em movimentos significativos

---

### **Alternativa 3: Logar√≠tmica + Pot√™ncia (Balanceada)**

```python
def fitness_log_power(prediction, price_change_pct):
    """
    Log para suavizar extremos + Pot√™ncia para amplificar m√©dios.
    Mais est√°vel que exponencial, mais agressiva que quadr√°tica.
    
    Escala: -8,000 a +8,000
    """
    pred_norm = np.clip(prediction, -1, 1)
    confidence = abs(pred_norm)
    magnitude = abs(price_change_pct)
    direction_match = np.sign(pred_norm) == np.sign(price_change_pct)
    
    # Base linear
    base = pred_norm * price_change_pct * 10000
    
    # Componente logar√≠tmica (suaviza extremos)
    log_component = np.log1p(magnitude * 100) * confidence * 500
    
    # Componente pot√™ncia (amplifica m√©dios)
    power_component = (confidence ** 1.5) * (magnitude ** 1.5) * 5000
    
    if direction_match:
        reward = base + log_component + power_component
    else:
        reward = base - log_component - power_component
    
    return reward

# Exemplos:
# M√©dio: pred=0.6, change=+0.3%
#   base = 0.6 √ó 0.003 √ó 10000 = 18
#   log = log(1.3) √ó 0.6 √ó 500 ‚âà 79
#   power = 0.46 √ó 0.016 √ó 5000 ‚âà 37
#   total ‚âà 134 (vs 18 linear!)
```

**Caracter√≠sticas**:
- ‚úÖ **Logar√≠tmica** evita explos√£o em extremos
- ‚úÖ **Pot√™ncia 1.5** amplifica valores m√©dios
- ‚úÖ Mais est√°vel que exponencial
- ‚úÖ Balanceada para diferentes volatilidades
- ‚úÖ Boa para cripto (volatilidade vari√°vel)

---

### **Alternativa 4: Sharpe-Inspired (Risco-Ajustado)**

```python
def fitness_sharpe_inspired(prediction, price_change_pct, volatility_window):
    """
    Inspirado no Sharpe Ratio: considera risco (volatilidade).
    Premia mais quando acerta em baixa volatilidade (mais dif√≠cil).
    
    Escala: -15,000 a +15,000
    """
    pred_norm = np.clip(prediction, -1, 1)
    confidence = abs(pred_norm)
    
    # Calcular volatilidade recente (desvio padr√£o dos √∫ltimos N movimentos)
    volatility = np.std(volatility_window) if len(volatility_window) > 0 else 0.01
    volatility = max(volatility, 0.001)  # Evitar divis√£o por zero
    
    # Base
    base = pred_norm * price_change_pct * 10000
    
    # Ajuste por risco (Sharpe-like)
    # Movimentos corretos em baixa volatilidade valem MAIS
    risk_adjusted_multiplier = 1.0 / (volatility * 100)
    risk_adjusted_multiplier = np.clip(risk_adjusted_multiplier, 0.5, 5.0)
    
    direction_match = np.sign(pred_norm) == np.sign(price_change_pct)
    
    if direction_match:
        # Bonus por acerto, ajustado pelo risco
        sharpe_bonus = (confidence ** 2) * abs(price_change_pct) * risk_adjusted_multiplier * 3000
        reward = base + sharpe_bonus
    else:
        # Penalidade menor se volatilidade alta (mais desculp√°vel errar)
        sharpe_penalty = (confidence ** 2) * abs(price_change_pct) / risk_adjusted_multiplier * 3000
        reward = base - sharpe_penalty
    
    return np.clip(reward, -15000, 15000)

# Exemplos:
# Baixa volatilidade (0.1%): pred=0.7, change=+0.2%, acerto
#   risk_mult = 1 / 0.1 = 10 ‚Üí clipped to 5
#   sharpe_bonus = 0.49 √ó 0.002 √ó 5 √ó 3000 ‚âà 15
#
# Alta volatilidade (1%): pred=0.7, change=+0.2%, acerto
#   risk_mult = 1 / 1 = 1
#   sharpe_bonus = 0.49 √ó 0.002 √ó 1 √ó 3000 ‚âà 3
#   (menos reward, pois √© "mais f√°cil" prever em alta volatilidade)
```

**Caracter√≠sticas**:
- ‚úÖ **Ajustado por risco** (volatilidade)
- ‚úÖ Premia mais acertos em mercado calmo
- ‚úÖ Mais tolerante com erros em mercado vol√°til
- ‚úÖ Incentiva consist√™ncia, n√£o sorte
- üéØ Excelente para produ√ß√£o (foca em edge real)

---

### **Alternativa 5: Multi-Scale H√≠brida (Complexa)** üî• MAIS AGRESSIVA

```python
def fitness_multi_scale_hybrid(prediction, price_change_pct):
    """
    Combina m√∫ltiplas escalas:
    - Linear para base
    - Quadr√°tica para confian√ßa
    - C√∫bica para movimentos extremos
    - Logar√≠tmica para suavizar
    
    Escala: -20,000 a +20,000
    """
    pred_norm = np.clip(prediction, -1, 1)
    confidence = abs(pred_norm)
    magnitude = abs(price_change_pct)
    direction_match = np.sign(pred_norm) == np.sign(price_change_pct)
    
    # 1. Base linear (peso 30%)
    linear = pred_norm * price_change_pct * 10000 * 0.3
    
    # 2. Quadr√°tica de confian√ßa (peso 30%)
    quadratic = (confidence ** 2) * magnitude * 8000 * 0.3
    
    # 3. C√∫bica para extremos (peso 25%)
    # S√≥ ativa se magnitude > 0.3% E confian√ßa > 0.5
    if magnitude > 0.003 and confidence > 0.5:
        cubic = (confidence ** 3) * (magnitude ** 2) * 15000 * 0.25
    else:
        cubic = 0
    
    # 4. Componente logar√≠tmica (peso 15%)
    logarithmic = np.log1p(confidence * magnitude * 100) * 1000 * 0.15
    
    # Combinar
    if direction_match:
        reward = linear + quadratic + cubic + logarithmic
    else:
        reward = linear - quadratic - cubic - logarithmic
    
    return np.clip(reward, -20000, 20000)

# Exemplos:
# EXTREMO: pred=0.9, change=+1%
#   linear = 0.9 √ó 0.01 √ó 10000 √ó 0.3 = 27
#   quadratic = 0.81 √ó 0.01 √ó 8000 √ó 0.3 = 19.44
#   cubic = 0.729 √ó 0.0001 √ó 15000 √ó 0.25 = 0.27
#   log = log(1.9) √ó 1000 √ó 0.15 ‚âà 98
#   total ‚âà 145 (vs 90 linear!)
```

**Caracter√≠sticas**:
- ‚úÖ **Multi-escala**: combina linear + quadr√°tica + c√∫bica + log
- ‚úÖ Extremamente agressiva para alta confian√ßa + movimento grande
- ‚úÖ Balanceada por pesos (evita domin√¢ncia de uma componente)
- ‚ö†Ô∏è Mais complexa de debugar
- üî• Diferencia√ß√£o m√°xima entre boas e m√°s previs√µes

---

## üìä Compara√ß√£o de Escalas

### Exemplo: Previs√£o correta forte (pred=0.8, change=+0.5%)

| F√≥rmula | Reward | Ganho vs Linear |
|---------|--------|-----------------|
| **Linear (atual)** | 400 | baseline |
| **Quadr√°tica** | 730 | +82% |
| **Exponencial** | 1,420 | +255% |
| **Log + Pot√™ncia** | 680 | +70% |
| **Sharpe** | 890 | +122% |
| **Multi-Scale** | 1,150 | +187% |

### Exemplo: Previs√£o errada forte (pred=0.8, change=-0.5%)

| F√≥rmula | Reward | Penalidade vs Linear |
|---------|--------|---------------------|
| **Linear (atual)** | -400 | baseline |
| **Quadr√°tica** | -730 | +82% pior |
| **Exponencial** | -1,420 | +255% pior |
| **Log + Pot√™ncia** | -680 | +70% pior |
| **Sharpe** | -890 | +122% pior |
| **Multi-Scale** | -1,150 | +187% pior |

---

## üéØ Recomenda√ß√µes

### Para M√°xima Performance: **Alternativa 1 (Quadr√°tica)** ‚≠ê
- Simples de implementar
- Est√°vel
- 2x diferencia√ß√£o vs linear
- Bom balan√ßo risco/benef√≠cio

### Para Foco em Movimentos Grandes: **Alternativa 2 (Exponencial)**
- Ignora ru√≠do
- Premia fortemente movimentos grandes
- Mais vol√°til, mas rewards maiores

### Para Estabilidade: **Alternativa 3 (Log + Pot√™ncia)**
- Mais conservadora
- Balanceada
- N√£o explode em extremos

### Para Trading Real: **Alternativa 4 (Sharpe)** üéØ
- Considera risco
- Mais "profissional"
- Foca em edge consistente

### Para Experimenta√ß√£o: **Alternativa 5 (Multi-Scale)** üî•
- Mais complexa
- Maior diferencia√ß√£o
- Pode achar padr√µes sutis

---

## üíª C√≥digo Pronto para Implementar

Todas as fun√ß√µes acima podem ser usadas assim:

```python
# No TradingEnvironmentRL.step():

# SUBSTITUIR:
reward = (prediction_value * 100) * (price_change_pct * 100)

# POR (escolha uma):
reward = fitness_quadratic_confidence(prediction_value, price_change_pct)
# OU
reward = fitness_exponential_threshold(prediction_value, price_change_pct)
# OU
reward = fitness_log_power(prediction_value, price_change_pct)
# OU
reward = fitness_sharpe_inspired(prediction_value, price_change_pct, volatility_window)
# OU
reward = fitness_multi_scale_hybrid(prediction_value, price_change_pct)
```

---

## üöÄ Impacto Esperado no Fitness

Com f√≥rmulas n√£o-lineares, voc√™ deve ver:

```
Linear atual:      ~30,000 fitness
Quadr√°tica:        ~50,000-60,000 fitness (+67%-100%)
Exponencial:       ~80,000-120,000 fitness (+167%-300%)
Log + Pot√™ncia:    ~45,000-55,000 fitness (+50%-83%)
Sharpe:            ~55,000-70,000 fitness (+83%-133%)
Multi-Scale:       ~70,000-100,000 fitness (+133%-233%)
```

**Todas levam voc√™ mais perto do threshold de produ√ß√£o (80k+)!** üéØ
